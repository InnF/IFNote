# 支持向量机（SVM）

## 基于最大间隔分隔数据

+ **优点：** 泛化错误率低，计算开销不大，结果易解释
+ **缺点：** 对参数调节和核函数的选择敏感，原始分类器不加修改仅适用于处理二类问题
+ **适用数据类型：** 数值型和标称型数据



SVM 的工作原理大致如下

<br />
<div align="center">
<img src="https://github.com/InnoFang/oh-my-study-notes/blob/image-hosting/Algo4ML/svm.jpg?raw=true"/>
</div>
<br />

上图中出现了决策边界、间隔、支持向量等名词，那么我们现在来简单解释一下

在这个二维图中，我们想要把数据集分割成两个部分，需要一条线；如果我们是在一个三位空间中，要分个数据集则需要一个面，因此我们可以说，我们要分割 N 维的数据集，则需要 N - 1 维的**决策边界**，那么这个决策边界我们就叫**超平面** （hyperplane）。

离分隔超平面最近的那些点即为**支持向量**（support vector）。我们希望找到**离分隔超平面最近的点，确保它们离分隔面的距离尽可能远**，这里点到分隔面的距离被称为**间隔** （margin）。

我们希望这个间隔尽可能大，只是因为如果我们犯错或者在有限数据上训练分类器的话，我们希望分类器尽可能健壮。

## 寻找最大间隔

我们中学的时候应该学过点到直线的距离公式

<br />
<div align="center">
<img src="https://github.com/InnoFang/oh-my-study-notes/blob/image-hosting/Algo4ML/distanceOfPointToLine.png?raw=true"/>
</div>
<br />

其中分子就相当于直线方程，分母就相当于各系数的平方和再开根号，推广到多维并用向量  W={A,B,..} 表示系数，向量 X={x1,x2,...} 表示未知数。那么学过线性代数的话，就知道我们可以使用这种方式来表示分隔超平面



<br />
<div align="center">
<img src="https://github.com/InnoFang/oh-my-study-notes/blob/image-hosting/Algo4ML/hyperplane.png?raw=true"/>
</div>
<br />



其中 b 为常数项。那么点到超平面的距离就可以用下式统一表示



<br />
<div align="center"> 
<img src="https://github.com/InnoFang/oh-my-study-notes/blob/image-hosting/Algo4ML/distanceOfPointToHyperplane.png?raw=true"/>
</div>
<br />